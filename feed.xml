<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://0xgeorgeassaad.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://0xgeorgeassaad.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-25T01:10:11+00:00</updated><id>https://0xgeorgeassaad.github.io/feed.xml</id><title type="html">blank</title><subtitle>A night owl interested in deep learning </subtitle><entry><title type="html">Sui Generis (ERC)</title><link href="https://0xgeorgeassaad.github.io/ERC/" rel="alternate" type="text/html" title="Sui Generis (ERC)"/><published>2025-06-22T00:00:00+00:00</published><updated>2025-06-22T00:00:00+00:00</updated><id>https://0xgeorgeassaad.github.io/ERC</id><content type="html" xml:base="https://0xgeorgeassaad.github.io/ERC/"><![CDATA[<p>I was fortunate enough to be awarded this amazing scholarship, and today I want to share a little of my experience with <strong><em>you</em></strong>, the upcoming recipients. I am a big critic of the notion that we all share the same underlying experience. I am adamant that my experience was unique, and yours will be too. That’s why I titled this blog “Sui Generis”, Latin for “of its own kind.” But even though my experience is unique, there are always lessons worth sharing that you might learn from. To be clear, I don’t consider myself worthy of giving advice. So, the following are not rules, but rather pointers or hints from my own journey that you might find handy.</p> <h3 id="make-long-lasting-friendships">Make <em>Long-Lasting</em> Friendships</h3> <p>First, I want to give you a glimpse of a day in my life as an undergraduate. I would wake up at 5:20 AM, having slept only about six hours. I lived about half an hour from the bus pickup point and needed to be there by 6:40 AM. From the moment I left my house, it took about two hours to reach the university. In total, that was four hours of commuting every day.</p> <p>This sounds brutal, but I genuinely didn’t mind the time I spent on the bus. This was because I always had the most interesting conversations about the most random topics with my dear friend, Mostafa. The crazy thing is that I even grew to enjoy my commute. I looked forward to those hours of discussion more than anything else in my day. Things that seem unbearable from the outside can pass smoothly or even become entertaining when you have the right company.</p> <p>This friendship even led to some unexpected adventures. For some reason, I had a running joke with my friends about the German Bundestag. So when I later visited Germany, I went out of my way to go to Berlin just to take a photo in front of the Bundestag. Here is an image of my very happy self in front of it<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>. You never know; sometimes, the jokes you share with friends can turn into reality.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Me_Bundestag-480.webp 480w,/assets/img/Me_Bundestag-800.webp 800w,/assets/img/Me_Bundestag-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/Me_Bundestag.jpeg" class="img-fluid rounded z-depth-1 d-block mx-auto" width="500px" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">In front of the German Bundestag.</figcaption> </figure> <p>I want to put great emphasis on “long-lasting.” You want to find friends you will still be talking to five, ten, or even fifteen years from now. Having no friends is better than having friendships that are transitory or superficial. Always look for quality, not quantity. It’s far superior to have a handful of deep, perpetual friendships than a huge number of shallow, transactional ones.</p> <h3 id="have-fun">Have Fun</h3> <p>This is one of those things we constantly need to be reminded of. We, myself included, often forget one of life’s greatest hacks: having fun. We get so consumed by where we are, where we want to go, and, mistakenly, where others are, that we completely lose the plot.</p> <p>You need to put a little extra effort into everything you do to ensure a fun element is embedded within it. I am telling you, you can absolutely have fun doing anything, even the most tedious tasks like completing an assignment or finishing a semester project. You just have to be mindful about it. I had the most fun while finishing a project just hours before the deadline or studying for an exam on the day it was scheduled<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>. Sometimes, a little adrenaline kick is all you need.</p> <h3 id="savor-every-moment">Savor Every Moment</h3> <p>Anyone working in the field of AI knows that we continuously move the goalposts. Once we built models that could perform classification and regression better than humans, we said, “This isn’t creative.” We needed models that could generate content like images or sound. Once we had these generative models, we thought we could rest assured and enjoy the win. Funnily enough, we now have models that can generate almost any type of content, but the goal has shifted again to Artificial General Intelligence (AGI). You can see the pattern here. We are trapped in an endless cycle; no matter what milestone we achieve, we always feel we are behind. We just need one more thing.</p> <p>This isn’t unique to the AI field. We are all victims of this mindset. Appreciate every single moment of your undergraduate journey to the fullest. If you are solving a challenging assignment, enjoy the struggle. If you are applying for that internship you’ve always wanted, enjoy the process and the anticipation. If this is your first semester and you are frustrated by the new system, enjoy the novelty. Let me tell you, even in the most difficult moments, there is always something to delight in. So, <em>savor every moment</em>.</p> <hr/> <h4 id="addendum"><strong>Addendum</strong></h4> <p>I didn’t talk about courses, exams, or anything related to studying because I believe those are the easiest things to figure out. You will become a master at these monotonous tasks after just a semester or two. Most importantly, keep your eye on your north star and follow it religiously. You will eventually graduate, but it’s the direction that truly matters.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>Sadly, the Bundestag was being renovated at the time. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>This was quite rare, but when it did happen, it was super exciting. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="misc"/><summary type="html"><![CDATA[Sui Generis (ERC)]]></summary></entry><entry><title type="html">Linear Algebra Part 01: Identities</title><link href="https://0xgeorgeassaad.github.io/blog/2024/LA-01/" rel="alternate" type="text/html" title="Linear Algebra Part 01: Identities"/><published>2024-07-19T00:00:00+00:00</published><updated>2024-07-19T00:00:00+00:00</updated><id>https://0xgeorgeassaad.github.io/blog/2024/LA-01</id><content type="html" xml:base="https://0xgeorgeassaad.github.io/blog/2024/LA-01/"><![CDATA[<style>.post-content details{color:var(--global-text-color);background-color:var(--global-code-bg-color);margin-top:0;padding:8px 12px;position:relative;border-radius:6px;display:block;margin-bottom:20px;max-width:100%;overflow:auto}.post-content details summary{color:var(--global-theme-color);cursor:pointer;font-weight:500}.post-content details p{margin-top:.5rem;margin-bottom:.5rem}</style> <p>Linear Algebra is a fascinating and foundational subject in mathematics. In this post, we are going to explore some of its most important identities with proofs and also shed light on some interesting and closely related results.</p> <h3 id="definitions-of-scalars-vector-and-matrices">Definitions of Scalars, Vector, and Matrices</h3> <ol> <li>Scalars: Scalars are numerical values from $\mathbb{R}$</li> <li>Vectors: Vectors are arrays of scalars where one of the dimensions is 1. A $1 \times d$ is called <em>a row vector</em>, whereas a $d \times 1$ is called a column vector. The entries in a vector are called <em>“components”</em>.</li> <li>Matrices: Matrices are the logical extension of vectors and can be thought of as rectangular arrays of scalars. To get an element inside the matrix, one has to define the row $i$ and column $j$ to obtain element $a_{ij}$ from matrix $A = [a_{ij}]_{n \times d}$</li> </ol> <h3 id="operations-with-scalars-and-vectors">Operations with Scalars and Vectors</h3> <p>Let 2 $d-$dimensional vectors be $\bar x = [x_1 \dots x_d]$ and $\bar y = [y_1 \dots y_d]$. They can be added component-wise as such:</p> \[\bar x + \bar y = [x_1 + y_1 \dots x_d + y_d]\] <p>and subtracted in the same way</p> \[\bar x - \bar y = [x_1 - y_1 \dots x_d - y_d]\] <p>A scalar $a$ can be multiplied by vector as such:</p> \[a\bar x = [ax_1 \dots ax_d]\] <p>The <em>dot product</em> is defined as the sum of the component-wise multiplication:</p> \[\bar x \cdot \bar y = \sum_{i=1}^{d} x_i y_i\] <p>The Euclidean norm is defined in terms of the dot product</p> \[\lVert \bar x \rVert^2 = \bar x \cdot \bar x = \sum_{i=1}^{d} x_i^2\] <p>The Euclidean norm is called the $L_2$-norm which can be generalized to any $L_p$-norm as follows</p> \[\lVert \bar x \rVert_p = \bar x \cdot \bar x = \left( \sum_{i=1}^{d} |x_i|^p \right)^{(1/p)}\] <p>The dot product satisfies the <em>Cauchy-Schwarz inequality</em> which sets an upper bound for the value of the dot product</p> \[\lvert \bar x \cdot \bar y \rvert \leq \lVert \bar x \rVert \lVert \bar y \rVert\] <p><strong>Proof:</strong> Let $\bar x^\prime$ and $\bar y^\prime$ be unit vectors constructed from $\bar x$ and $\bar y$ such that \(\bar x^\prime = \dfrac{\bar x}{\lVert \bar x \rVert}\) and \(\bar y^\prime = \dfrac{\bar y}{\lVert \bar y \rVert}\)</p> <p>We show that $\lvert \bar x^\prime \cdot \bar y^\prime \rvert \leq 1$ by calculating $\lVert \bar x^\prime - \bar y^\prime \rVert^2$ and $\lVert \bar x^\prime + \bar y^\prime \rVert^2$ as such</p> \[\begin{aligned} \lVert \bar x^\prime - \bar y^\prime \rVert^2 &amp;= (\bar x^\prime - \bar y^\prime) \cdot (\bar x^\prime - \bar y^\prime) = \lVert \bar x^\prime \rVert + \lVert \bar y^\prime \rVert - 2 \bar x^\prime \cdot \bar y^\prime = 2 - 2 \bar x^\prime \cdot \bar y^\prime \\\\ \lVert \bar x^\prime + \bar y^\prime \rVert^2 &amp;= (\bar x^\prime + \bar y^\prime) \cdot (\bar x^\prime + \bar y^\prime) = \lVert \bar x^\prime \rVert + \lVert \bar y^\prime \rVert + 2 \bar x^\prime \cdot \bar y^\prime = 2 + 2 \bar x^\prime \cdot \bar y^\prime \end{aligned}\] <p>Since both $\lVert \bar x^\prime - \bar y^\prime \rVert^2$ and $\lVert \bar x^\prime + \bar y^\prime \rVert^2$ are nonnegative, then $\lvert \bar x^\prime \cdot \bar y^\prime \rvert \leq 1$</p> <p>Now, we scale the unit vectors to obtain the general inequality</p> \[\begin{aligned} \lvert \bar x^\prime \cdot \bar y^\prime \rvert &amp;\leq 1 \\\\ \lVert \bar x \rVert \lVert \bar y \rVert \lvert \bar x^\prime \cdot \bar y^\prime \rvert &amp;\leq \lVert \bar x \rVert \lVert \bar y \rVert \\\\ \lvert \bar x \cdot \bar y \rvert &amp;\leq \lVert \bar x \rVert \lVert \bar y \rVert \end{aligned}\] <p>Using the <em>Cauchy-Schwarz inequality</em>, we can also prove the triangle inequality which states that, in a triangle formed by $\bar x$ and $\bar y$, the side length of $\lVert \bar x - \bar y \rVert$ is no longer than the sum of the two other sides</p> \[\lVert \bar x - \bar y \rVert \leq \lVert \bar x \rVert + \lVert \bar y \rVert\] <p><strong>Proof:</strong> Since both sides of the triangle inequality are nonnegative, we only need to show that it still holds after squaring both sides.</p> \[\begin{aligned} \lvert \bar x \cdot \bar y \rvert &amp;\leq \lVert \bar x \rVert \lVert \bar y \rVert \\ -\lVert \bar x \rVert \lVert \bar y \rVert &amp;\leq \bar x \cdot \bar y \leq \lVert \bar x \rVert \lVert \bar y \rVert \\ \bar x \cdot \bar y &amp;\geq - \lVert \bar x \rVert \lVert \bar y \rVert \\ -2\bar x \cdot \bar y &amp;\leq 2 \lVert \bar x \rVert \lVert \bar y \rVert \\ \lVert \bar x \rVert^2 + \lVert \bar y \rVert^2 -2\bar x \cdot \bar y &amp;\leq \lVert \bar x \rVert^2 + \lVert \bar y \rVert^2+ 2 \lVert \bar x \rVert \lVert \bar y \rVert \\ (\bar x - \bar y) \cdot (\bar x - \bar y) &amp;\leq (\lVert \bar x \rVert +\lVert \bar y \rVert)^2 \\ (\lVert \bar x - \bar y \rVert)^2 &amp;\leq (\lVert \bar x \rVert + \lVert \bar y \rVert)^2 \end{aligned}\] <h3 id="operations-with-vectors-and-matrices">Operations with Vectors and Matrices</h3> <p>The transpose of a matrix is obtained by flipping its rows and columns such that the $(i, j)th$ entry of the transpose is the same as the $(j, i)th$ entry of the original matrix. Therefore, the transpose of an $n \times d$ matrix is a $d \times n$ matrix. The transpose of a matrix $A$ is denoted by $A^T$. An example of the transpose of $A$ is shown:</p> \[\begin{bmatrix} a_{11} &amp; a_{12} \\ a_{21} &amp; a_{22} \end{bmatrix}^T = \begin{bmatrix} a_{11} &amp; a_{21} \\ a_{12} &amp; a_{22} \end{bmatrix}\] <p>It immediately follows that $(A^T)^T = A$ and that the transpose of the sum is the sum of the transpose: \((A+B)^T = A^T + B^T\)</p> <p>For the matrix-vector product of $n \times d$ matrix $A$ with $d \times 1$ vector $\bar x$, we can observe that the elements of $\bar x$ act as weights for each column of $A$</p> \[\begin{bmatrix} a_{11} &amp; a_{12} \\ a_{21} &amp; a_{22} \\ a_{31} &amp; a_{32} \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} x_1 a_{11} + x_2 a_{12} \\ x_1 a_{21} + x_2 a_{22} \\ x_1 a_{31} + x_2 a_{32} \end{bmatrix}\] <p>As a general form: $ A \bar x = \sum_{i=0}^{d} x_i \bar a_i$</p> <p>Now, we define outer products which can be performed between vectors of different lengths</p> \[\bar x \bar y ^T = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} \begin{bmatrix} y_1 &amp; y_2 &amp; y_3 \end{bmatrix}= \begin{bmatrix} y_1x_1 &amp; y_2x_1 &amp; y_3x_1 \\ y_1x_2 &amp; y_2x_2 &amp; y_3x_2 \\ y_1x_3 &amp; y_2x_3 &amp; y_3x_3 \\ \end{bmatrix}\] <p>We can also show that if the outer product between an $n\times1$ vector is and a $1\times d$ vector result in an $n\times d$ matrix with the following properties: (i) Every row is a multiple of every other row, and (ii) every column is a multiple of every other column:</p> \[\begin{bmatrix} a_1 \\ a_2 \\ \vdots \\ a_n \end{bmatrix}_{n \times 1} \begin{bmatrix} b_1 &amp; b_2 &amp; \dots &amp; b_d \end{bmatrix}_{1 \times d} = \begin{bmatrix} a_1b_1 &amp; a_1b_2 &amp; \dots &amp; a_1b_d \\ a_2b_1 &amp; a_2b_2 &amp; \dots &amp; a_2b_d \\ \vdots &amp; \ddots &amp; \ddots &amp; \vdots \\ a_nb_1 &amp; a_nb_2 &amp; \dots &amp; a_nb_d \\ \end{bmatrix}_{n \times d}\] <p>It is clear that each row $\bar R_i = \dfrac{\bar R_j a_i}{a_j}$ and that each column $\bar C_i = \dfrac{\bar C_j b_i}{b_j}$</p> <p><strong>Exercise:</strong> Let A be an $1000000 \times 2$ matrix. Suppose you have to compute the $2 \times 1000000$ matrix $A^T AA^T$ on a computer with limited memory. Would you prefer to compute $(A^T A)A^T$ or would you prefer to compute $A^T (AA^T)$?.</p> <details><summary>Click here for the answer.</summary> <p><strong>Sol:</strong></p> \[\begin{aligned} (A^T A)A^T &amp;\rightarrow (2 \times 2) (2 \times 1000000) \ \text{ [lower memory usage]} \\ A^T (AA^T) &amp;\rightarrow (2 \times 1000000) (1000000 \times 1000000) \end{aligned}\] </details> <p><strong>Exercise:</strong> Let $D$ be an $n \times d$ matrix for which each column sums to 0. Let $A$ be an arbitrary $d \times d$ matrix. Show that the sum of each column of $DA$ is also zero.</p> <details><summary>Click here for the answer.</summary> <p><strong>Sol:</strong></p> \[\begin{aligned} \sum_{i=1}^{n} (DA)_{ij} = \sum_{i=1}^{n} \sum_{k=1}^{d} D_{ik} A_{kj} = \sum_{k=1}^{d} A_{kj} \sum_{i=1}^{n} D_{ik} = 0 \end{aligned}\] </details> <p><strong>Exercise:</strong> Show that \((A_1A_2A_3 \dots A_n)^T = A_n^T A_{n-1}^T \dots A_{2}^T A_{1}^T\)</p> <div class="mb-4"> <details><summary>Click here for the answer.</summary> <p><strong>Sol:</strong></p> \[(A_1A_2A_3 \dots A_n)^T = A_n^T A_{n-2}^T (A_1A_2A_3 \dots A_{n-2})^T = A_n^T A_{n-1}^T \dots A_{2}^T A_{1}\] </details> </div> <p>A matrix is called symmetric if it is square and equal to its transpose \(A=A^T\)</p> <p><strong>Exercise:</strong> If A and B are symmetric matrices, then show that AB is symmetric if and only if AB = BA</p> <div class="distill-details-wrapper"> <details><summary>Click here for the answer.</summary> <p><strong>Sol:</strong></p> \[AB = (AB)^T = B^T A^T = BA\] </details> <div> </div></div>]]></content><author><name></name></author><category term="math"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Reimplementing python’s heapq module</title><link href="https://0xgeorgeassaad.github.io/blog/2024/python-heapq/" rel="alternate" type="text/html" title="Reimplementing python’s heapq module"/><published>2024-05-28T00:00:00+00:00</published><updated>2024-05-28T00:00:00+00:00</updated><id>https://0xgeorgeassaad.github.io/blog/2024/python-heapq</id><content type="html" xml:base="https://0xgeorgeassaad.github.io/blog/2024/python-heapq/"><![CDATA[<h3 id="difference-between-priority-queue-and-heap">Difference between Priority Queue and Heap</h3> <p>It’s important to note the difference between Priority Queue and Heap. Priority Queue is an <em>abstract data-type</em> that supports a specified set of operations but can be implemented using various data structures.</p> <p>A priority queue is similar to a normal queue with the only difference being that the order in which elements are removed from the queue depends on their priority not their time of arrival (addition), and as such, the data inserted into a priority queue must be comparable so that they can be ordered from least to greatest or vice versa.</p> <p>A priority queue supports the following set of operations:</p> <ul> <li><code class="language-plaintext highlighter-rouge">is_empty()</code>: checks whether the queue has no elements</li> <li><code class="language-plaintext highlighter-rouge">add(elem, prio)</code>: adds an element with a specified priority to the queue</li> <li><code class="language-plaintext highlighter-rouge">poll()</code>: removes the element with highest priority from the queue</li> </ul> <p>A priority queue can be implemented using a list, but it will be very inefficient. That’s why we will implement it using a heap which is a tree-based data structure that satisfies the heap invariant<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>.</p> <p>The heap invariant states that the value of the parent node is smaller than the value of its children node (in case of min heap).</p> <h3 id="representation-of-a-heap">Representation of a Heap</h3> <p>Since a heap is a tree, it can represented using a pointers approach by creating a <code class="language-plaintext highlighter-rouge">node</code> class with properties <code class="language-plaintext highlighter-rouge">leftChild</code> and <code class="language-plaintext highlighter-rouge">rightChild</code>, but there is a much better and simpler representation using a simple list. So, for any parent at index $i$, we can calculate the indices of children as such:</p> \[\begin{aligned} \text{Left Child index } &amp;= 2 i+ 1 \\\\ \text{Right Child index } &amp;= 2 i+ 2 \\\\ \end{aligned}\] <p>Here is an example for a heap represented using a list</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#    0   
#   / \  
#  2   3 
# / \ / \
# 4 5 6 4
</span><span class="n">heap</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>
</code></pre></div></div> <h3 id="turning-a-min-heap-into-a-max-heap">Turning a Min Heap into a Max Heap</h3> <p>Python’s original <code class="language-plaintext highlighter-rouge">heapq</code> as well as our reimplementation supports only a min heap. So, how can we turn that into a max heap?</p> <p>Since all elements in the heap implement a comparator interface, we can simply negate the comparator which, in effect, will result in the parent being larger than or equal to its children.</p> <p>One nice trick can be used when the elements themselves are numbers or when the priority is a number, We simply multiply the number by $-1$ before insertion and then multiply it back by $-1$ after removal.</p> <h3 id="adding-elements-to-the-heap">Adding elements to the heap</h3> <p>We want to maintain the complete binary tree property to achieve the nice $O(\log(n))$ runtime. We can do this by inserting any new element at the bottom leftmost position and then swimming the element to maintain the heap invariant.</p> <p>Now, we discuss the sift up algorithm starting at index $i$:</p> <ol> <li>Set <code class="language-plaintext highlighter-rouge">k = i</code> and <code class="language-plaintext highlighter-rouge">parent = (k - 1) // 2</code></li> <li>If node is smaller than parent, <ul> <li>swap node $k$ with parent</li> <li>set <code class="language-plaintext highlighter-rouge">k = parent</code> and <code class="language-plaintext highlighter-rouge">parent = (k - 1) // 2</code></li> <li>return to step 1</li> </ul> </li> <li>else, terminate</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># O(log(n))
</span><span class="k">def</span> <span class="nf">heappush</span><span class="p">(</span><span class="n">heap</span><span class="p">,</span> <span class="n">elem</span><span class="p">):</span>
    <span class="n">heap</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span>
    <span class="nf">swim</span><span class="p">(</span><span class="n">heap</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">heap</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">swim</span><span class="p">(</span><span class="n">heap</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">parent</span> <span class="o">=</span> <span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="k">while</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">heap</span><span class="p">[</span><span class="n">parent</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">heap</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
        <span class="n">heap</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">heap</span><span class="p">[</span><span class="n">parent</span><span class="p">]</span> <span class="o">=</span> <span class="n">heap</span><span class="p">[</span><span class="n">parent</span><span class="p">],</span> <span class="n">heap</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">parent</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span> 
</code></pre></div></div> <h3 id="removing-elements-from-the-heap">Removing elements from the heap</h3> <p>When polling, the root is always located at index $0$. So, we extract <code class="language-plaintext highlighter-rouge">heap[0]</code> and swap the root <code class="language-plaintext highlighter-rouge">heap[0]</code> with the bottom rightmost leaf located at the end of the list <code class="language-plaintext highlighter-rouge">heap[-1]</code>. Then, to maintain the heap invariant we sink the element location at the root starting at index $0$.</p> <p>Now, we discuss the sinking algorithm starting at index $i$:</p> <p>One important note is that when comparing the node with its children and in case of a tie between the left and right node, we always default to the left child.</p> <ol> <li>Set <code class="language-plaintext highlighter-rouge">k = i</code></li> <li>Set <code class="language-plaintext highlighter-rouge">left = 2*k + 1</code>, <code class="language-plaintext highlighter-rouge">right = 2*k + 2</code></li> <li>Set <code class="language-plaintext highlighter-rouge">smallest = left</code></li> <li>if the right element is smaller than the left element <ul> <li>Set <code class="language-plaintext highlighter-rouge">smallest = right</code></li> </ul> </li> <li>if $k$ is $\leq$ $parent$: <ul> <li>terminate</li> </ul> </li> <li>else, <ul> <li>swap node $k$ with smallest</li> <li>set <code class="language-plaintext highlighter-rouge">k = smallest</code></li> <li>return to step 2</li> </ul> </li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># O(log(n))
</span><span class="k">def</span> <span class="nf">heappop</span><span class="p">(</span><span class="n">heap</span><span class="p">):</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">heap</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">heap</span><span class="p">.</span><span class="nf">pop</span><span class="p">()</span>
    <span class="n">root</span> <span class="o">=</span> <span class="n">heap</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">heap</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">heap</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">heap</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">heap</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">heap</span><span class="p">.</span><span class="nf">pop</span><span class="p">()</span>
    <span class="nf">sink</span><span class="p">(</span><span class="n">heap</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">root</span>
<span class="k">def</span> <span class="nf">sink</span><span class="p">(</span><span class="n">heap</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">left</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">right</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="n">smallest</span> <span class="o">=</span> <span class="n">left</span>
        <span class="k">if</span> <span class="n">right</span> <span class="o">&lt;</span> <span class="nf">len</span><span class="p">(</span><span class="n">heap</span><span class="p">)</span> <span class="ow">and</span> <span class="n">heap</span><span class="p">[</span><span class="n">right</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">heap</span><span class="p">[</span><span class="n">left</span><span class="p">]:</span>
            <span class="n">smallest</span> <span class="o">=</span> <span class="n">right</span>
        <span class="k">if</span> <span class="n">left</span> <span class="o">&gt;=</span> <span class="nf">len</span><span class="p">(</span><span class="n">heap</span><span class="p">)</span> <span class="ow">or</span> <span class="n">heap</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">heap</span><span class="p">[</span><span class="n">smallest</span><span class="p">]:</span>
            <span class="k">break</span>
        <span class="n">heap</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">heap</span><span class="p">[</span><span class="n">smallest</span><span class="p">]</span> <span class="o">=</span> <span class="n">heap</span><span class="p">[</span><span class="n">smallest</span><span class="p">],</span> <span class="n">heap</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">smallest</span>
</code></pre></div></div> <h3 id="heapifying-a-list">Heapifying a list</h3> <p>If we already have an unsorted list and we want to turn it into a heap, the naive approach would be creating a new heap and then <code class="language-plaintext highlighter-rouge">heappush</code> each element from the list, but that would result in a runtime of $O(n\log(n))$.</p> <p>There is a more efficient way that runs in a runtime of only $O(n)$. Now, the heapify algorithm is quite simple, but it’s quite hard to prove its runtime.</p> <p>If you are interested, you can find the proof here<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>.</p> <p>We start from the last parent (located in the middle of the list) and then sink each parent down.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># O(n)
</span><span class="k">def</span> <span class="nf">heapify</span><span class="p">(</span><span class="n">heap</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">heap</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="nf">sink</span><span class="p">(</span><span class="n">heap</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
</code></pre></div></div> <h3 id="nlargest-or-nsmallest">nlargest (or nsmallest)</h3> <p>Now, imagine we want to get the $k$ largest elements from unsorted list of size $n$. The naive approach would be to first heapify the list and then pop $k$ elements from the newly built heap, but that would result in a runtime of $O(n)$ to heapify the list and a $O(\log(n))$ for each <code class="language-plaintext highlighter-rouge">heapop</code> operation resulting in a total runtime of $ O(n+ k\log(n))$ and $O(n)$ memory.</p> <p>There is another approach which is faster but might not be entirely clear to you at first. The key is to actually build a heap of only size $k$ and then traverse the rest of the list and only pop the root if the current array element <code class="language-plaintext highlighter-rouge">arr[i]</code> is larger. To see why at the end of traversal the heap would contain the $k$ largest elements, assume that the list was sorted. If we take the first $k$ elements and then heapify them, by looking at the $k+1$ element in the list, we immediately see that it’s larger than the root of the heap. Then, we pop the root and insert this new element. If we continue in this manner, we will have the $k$ largest elements by the end of the traversal. The last step would be sorting the heap.</p> <p>Now, Let’s see why it’s efficient.</p> <ul> <li>$O(\log(k))$: heapify first $k$ elements from the list</li> <li>$O((n-k) \log(k))$: at most we possibly would have to replace root of heap with each single element remaining in the list $(n-k)$ elements. (if the list was sorted)</li> <li>$O(k \log(k))$: sort final heap</li> </ul> <p>Thus, the total runtime is $ \log(k) + (n-k) \log(k)+ k \log(k) = (n+1)\log(k) \approx O(n\log(k))$ and $O(k)$ memory.</p> <p>We see that the second approach is better:</p> <ul> <li>memory: $O(k) &lt; O(n)$</li> <li>time: $O(n\log(k)) &lt; O(n+ k\log(n))$</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># O(nlog(k))
</span><span class="k">def</span> <span class="nf">nlargest</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">heap</span> <span class="o">=</span> <span class="n">arr</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span>
    <span class="nf">heapify</span><span class="p">(</span><span class="n">heap</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">arr</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">arr</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">heap</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="nf">heappop</span><span class="p">(</span><span class="n">heap</span><span class="p">)</span>
            <span class="nf">heappush</span><span class="p">(</span><span class="n">heap</span><span class="p">,</span> <span class="n">arr</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">heap</span><span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">heap</span>
</code></pre></div></div> <h3 id="congrats">Congrats!!</h3> <p>Pat yourself on the back! We have just implemented the python’s <code class="language-plaintext highlighter-rouge">heapq</code> module. During writing, I didn’t look at the original source code, but if you are interested, here is the original source code of the <code class="language-plaintext highlighter-rouge">heapq</code> module<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>. Just note that the implementation of python would be faster because it uses a byte-compiled version, but nonetheless you can look at the python source code to learn from it.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p><a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">Heap (data structure) - Wikipedia</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p><a href="https://www.cs.umd.edu/~meesh/351/mount/lectures/lect14-heapsort-analysis-part.pdf">Heapify proof</a> <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p><a href="https://github.com/python/cpython/blob/3.12/Lib/heapq.py">Python’s heaapq implementation</a> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="code"/><summary type="html"><![CDATA[Difference between Priority Queue and Heap]]></summary></entry></feed>