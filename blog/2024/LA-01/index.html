<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="_QulXh9JitynR6CjGBqsroG6I5hve1zFQ3L7Jo_bf0o"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Linear Algebra Part 01: Identities | George Assaad </title> <meta name="author" content="George Assaad"> <meta name="description" content="A night owl interested in deep learning "> <meta name="keywords" content="George Assaad, Clemson, deep learning, computer science, cs, mathematics, math, blog"> <meta property="og:site_name" content="George Assaad"> <meta property="og:type" content="article"> <meta property="og:title" content="George Assaad | Linear Algebra Part 01: Identities"> <meta property="og:url" content="https://0xgeorgeassaad.github.io/blog/2024/LA-01/"> <meta property="og:description" content="A night owl interested in deep learning "> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Linear Algebra Part 01: Identities"> <meta name="twitter:description" content="A night owl interested in deep learning "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@100..900&amp;display=swap" rel="stylesheet"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?cb2b3c5cf03c74bfbaae273f2e153003"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://0xgeorgeassaad.github.io/blog/2024/LA-01/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">George</span> Assaad </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Linear Algebra Part 01: Identities</h1> <p class="post-meta"> Created on July 19, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> math</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <style>.post-content details{color:var(--global-text-color);background-color:var(--global-code-bg-color);margin-top:0;padding:8px 12px;position:relative;border-radius:6px;display:block;margin-bottom:20px;max-width:100%;overflow:auto}.post-content details summary{color:var(--global-theme-color);cursor:pointer;font-weight:500}.post-content details p{margin-top:.5rem;margin-bottom:.5rem}</style> <p>Linear Algebra is a fascinating and foundational subject in mathematics. In this post, we are going to explore some of its most important identities with proofs and also shed light on some interesting and closely related results.</p> <h3 id="definitions-of-scalars-vector-and-matrices">Definitions of Scalars, Vector, and Matrices</h3> <ol> <li>Scalars: Scalars are numerical values from $\mathbb{R}$</li> <li>Vectors: Vectors are arrays of scalars where one of the dimensions is 1. A $1 \times d$ is called <em>a row vector</em>, whereas a $d \times 1$ is called a column vector. The entries in a vector are called <em>“components”</em>.</li> <li>Matrices: Matrices are the logical extension of vectors and can be thought of as rectangular arrays of scalars. To get an element inside the matrix, one has to define the row $i$ and column $j$ to obtain element $a_{ij}$ from matrix $A = [a_{ij}]_{n \times d}$</li> </ol> <h3 id="operations-with-scalars-and-vectors">Operations with Scalars and Vectors</h3> <p>Let 2 $d-$dimensional vectors be $\bar x = [x_1 \dots x_d]$ and $\bar y = [y_1 \dots y_d]$. They can be added component-wise as such:</p> \[\bar x + \bar y = [x_1 + y_1 \dots x_d + y_d]\] <p>and subtracted in the same way</p> \[\bar x - \bar y = [x_1 - y_1 \dots x_d - y_d]\] <p>A scalar $a$ can be multiplied by vector as such:</p> \[a\bar x = [ax_1 \dots ax_d]\] <p>The <em>dot product</em> is defined as the sum of the component-wise multiplication:</p> \[\bar x \cdot \bar y = \sum_{i=1}^{d} x_i y_i\] <p>The Euclidean norm is defined in terms of the dot product</p> \[\lVert \bar x \rVert^2 = \bar x \cdot \bar x = \sum_{i=1}^{d} x_i^2\] <p>The Euclidean norm is called the $L_2$-norm which can be generalized to any $L_p$-norm as follows</p> \[\lVert \bar x \rVert_p = \bar x \cdot \bar x = \left( \sum_{i=1}^{d} |x_i|^p \right)^{(1/p)}\] <p>The dot product satisfies the <em>Cauchy-Schwarz inequality</em> which sets an upper bound for the value of the dot product</p> \[\lvert \bar x \cdot \bar y \rvert \leq \lVert \bar x \rVert \lVert \bar y \rVert\] <p><strong>Proof:</strong> Let $\bar x^\prime$ and $\bar y^\prime$ be unit vectors constructed from $\bar x$ and $\bar y$ such that \(\bar x^\prime = \dfrac{\bar x}{\lVert \bar x \rVert}\) and \(\bar y^\prime = \dfrac{\bar y}{\lVert \bar y \rVert}\)</p> <p>We show that $\lvert \bar x^\prime \cdot \bar y^\prime \rvert \leq 1$ by calculating $\lVert \bar x^\prime - \bar y^\prime \rVert^2$ and $\lVert \bar x^\prime + \bar y^\prime \rVert^2$ as such</p> \[\begin{aligned} \lVert \bar x^\prime - \bar y^\prime \rVert^2 &amp;= (\bar x^\prime - \bar y^\prime) \cdot (\bar x^\prime - \bar y^\prime) = \lVert \bar x^\prime \rVert + \lVert \bar y^\prime \rVert - 2 \bar x^\prime \cdot \bar y^\prime = 2 - 2 \bar x^\prime \cdot \bar y^\prime \\\\ \lVert \bar x^\prime + \bar y^\prime \rVert^2 &amp;= (\bar x^\prime + \bar y^\prime) \cdot (\bar x^\prime + \bar y^\prime) = \lVert \bar x^\prime \rVert + \lVert \bar y^\prime \rVert + 2 \bar x^\prime \cdot \bar y^\prime = 2 + 2 \bar x^\prime \cdot \bar y^\prime \end{aligned}\] <p>Since both $\lVert \bar x^\prime - \bar y^\prime \rVert^2$ and $\lVert \bar x^\prime + \bar y^\prime \rVert^2$ are nonnegative, then $\lvert \bar x^\prime \cdot \bar y^\prime \rvert \leq 1$</p> <p>Now, we scale the unit vectors to obtain the general inequality</p> \[\begin{aligned} \lvert \bar x^\prime \cdot \bar y^\prime \rvert &amp;\leq 1 \\\\ \lVert \bar x \rVert \lVert \bar y \rVert \lvert \bar x^\prime \cdot \bar y^\prime \rvert &amp;\leq \lVert \bar x \rVert \lVert \bar y \rVert \\\\ \lvert \bar x \cdot \bar y \rvert &amp;\leq \lVert \bar x \rVert \lVert \bar y \rVert \end{aligned}\] <p>Using the <em>Cauchy-Schwarz inequality</em>, we can also prove the triangle inequality which states that, in a triangle formed by $\bar x$ and $\bar y$, the side length of $\lVert \bar x - \bar y \rVert$ is no longer than the sum of the two other sides</p> \[\lVert \bar x - \bar y \rVert \leq \lVert \bar x \rVert + \lVert \bar y \rVert\] <p><strong>Proof:</strong> Since both sides of the triangle inequality are nonnegative, we only need to show that it still holds after squaring both sides.</p> \[\begin{aligned} \lvert \bar x \cdot \bar y \rvert &amp;\leq \lVert \bar x \rVert \lVert \bar y \rVert \\ -\lVert \bar x \rVert \lVert \bar y \rVert &amp;\leq \bar x \cdot \bar y \leq \lVert \bar x \rVert \lVert \bar y \rVert \\ \bar x \cdot \bar y &amp;\geq - \lVert \bar x \rVert \lVert \bar y \rVert \\ -2\bar x \cdot \bar y &amp;\leq 2 \lVert \bar x \rVert \lVert \bar y \rVert \\ \lVert \bar x \rVert^2 + \lVert \bar y \rVert^2 -2\bar x \cdot \bar y &amp;\leq \lVert \bar x \rVert^2 + \lVert \bar y \rVert^2+ 2 \lVert \bar x \rVert \lVert \bar y \rVert \\ (\bar x - \bar y) \cdot (\bar x - \bar y) &amp;\leq (\lVert \bar x \rVert +\lVert \bar y \rVert)^2 \\ (\lVert \bar x - \bar y \rVert)^2 &amp;\leq (\lVert \bar x \rVert + \lVert \bar y \rVert)^2 \end{aligned}\] <h3 id="operations-with-vectors-and-matrices">Operations with Vectors and Matrices</h3> <p>The transpose of a matrix is obtained by flipping its rows and columns such that the $(i, j)th$ entry of the transpose is the same as the $(j, i)th$ entry of the original matrix. Therefore, the transpose of an $n \times d$ matrix is a $d \times n$ matrix. The transpose of a matrix $A$ is denoted by $A^T$. An example of the transpose of $A$ is shown:</p> \[\begin{bmatrix} a_{11} &amp; a_{12} \\ a_{21} &amp; a_{22} \end{bmatrix}^T = \begin{bmatrix} a_{11} &amp; a_{21} \\ a_{12} &amp; a_{22} \end{bmatrix}\] <p>It immediately follows that $(A^T)^T = A$ and that the transpose of the sum is the sum of the transpose: \((A+B)^T = A^T + B^T\)</p> <p>For the matrix-vector product of $n \times d$ matrix $A$ with $d \times 1$ vector $\bar x$, we can observe that the elements of $\bar x$ act as weights for each column of $A$</p> \[\begin{bmatrix} a_{11} &amp; a_{12} \\ a_{21} &amp; a_{22} \\ a_{31} &amp; a_{32} \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} x_1 a_{11} + x_2 a_{12} \\ x_1 a_{21} + x_2 a_{22} \\ x_1 a_{31} + x_2 a_{32} \end{bmatrix}\] <p>As a general form: $ A \bar x = \sum_{i=0}^{d} x_i \bar a_i$</p> <p>Now, we define outer products which can be performed between vectors of different lengths</p> \[\bar x \bar y ^T = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} \begin{bmatrix} y_1 &amp; y_2 &amp; y_3 \end{bmatrix}= \begin{bmatrix} y_1x_1 &amp; y_2x_1 &amp; y_3x_1 \\ y_1x_2 &amp; y_2x_2 &amp; y_3x_2 \\ y_1x_3 &amp; y_2x_3 &amp; y_3x_3 \\ \end{bmatrix}\] <p>We can also show that if the outer product between an $n\times1$ vector is and a $1\times d$ vector result in an $n\times d$ matrix with the following properties: (i) Every row is a multiple of every other row, and (ii) every column is a multiple of every other column:</p> \[\begin{bmatrix} a_1 \\ a_2 \\ \vdots \\ a_n \end{bmatrix}_{n \times 1} \begin{bmatrix} b_1 &amp; b_2 &amp; \dots &amp; b_d \end{bmatrix}_{1 \times d} = \begin{bmatrix} a_1b_1 &amp; a_1b_2 &amp; \dots &amp; a_1b_d \\ a_2b_1 &amp; a_2b_2 &amp; \dots &amp; a_2b_d \\ \vdots &amp; \ddots &amp; \ddots &amp; \vdots \\ a_nb_1 &amp; a_nb_2 &amp; \dots &amp; a_nb_d \\ \end{bmatrix}_{n \times d}\] <p>It is clear that each row $\bar R_i = \dfrac{\bar R_j a_i}{a_j}$ and that each column $\bar C_i = \dfrac{\bar C_j b_i}{b_j}$</p> <p><strong>Exercise:</strong> Let A be an $1000000 \times 2$ matrix. Suppose you have to compute the $2 \times 1000000$ matrix $A^T AA^T$ on a computer with limited memory. Would you prefer to compute $(A^T A)A^T$ or would you prefer to compute $A^T (AA^T)$?.</p> <details><summary>Click here for the answer.</summary> <p><strong>Sol:</strong></p> \[\begin{aligned} (A^T A)A^T &amp;\rightarrow (2 \times 2) (2 \times 1000000) \ \text{ [lower memory usage]} \\ A^T (AA^T) &amp;\rightarrow (2 \times 1000000) (1000000 \times 1000000) \end{aligned}\] </details> <p><strong>Exercise:</strong> Let $D$ be an $n \times d$ matrix for which each column sums to 0. Let $A$ be an arbitrary $d \times d$ matrix. Show that the sum of each column of $DA$ is also zero.</p> <details><summary>Click here for the answer.</summary> <p><strong>Sol:</strong></p> \[\begin{aligned} \sum_{i=1}^{n} (DA)_{ij} = \sum_{i=1}^{n} \sum_{k=1}^{d} D_{ik} A_{kj} = \sum_{k=1}^{d} A_{kj} \sum_{i=1}^{n} D_{ik} = 0 \end{aligned}\] </details> <p><strong>Exercise:</strong> Show that \((A_1A_2A_3 \dots A_n)^T = A_n^T A_{n-1}^T \dots A_{2}^T A_{1}^T\)</p> <div class="mb-4"> <details><summary>Click here for the answer.</summary> <p><strong>Sol:</strong></p> \[(A_1A_2A_3 \dots A_n)^T = A_n^T A_{n-2}^T (A_1A_2A_3 \dots A_{n-2})^T = A_n^T A_{n-1}^T \dots A_{2}^T A_{1}\] </details> </div> <p>A matrix is called symmetric if it is square and equal to its transpose \(A=A^T\)</p> <p><strong>Exercise:</strong> If A and B are symmetric matrices, then show that AB is symmetric if and only if AB = BA</p> <div class="distill-details-wrapper"> <details><summary>Click here for the answer.</summary> <p><strong>Sol:</strong></p> \[AB = (AB)^T = B^T A^T = BA\] </details> <div> </div> </div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/ERC/">Sui Generis (ERC)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/python-heapq/">Reimplementing python's heapq module</a> </li> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 George Assaad. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-0D9DTLDYE6"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-0D9DTLDYE6');
  </script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> </body> </html>